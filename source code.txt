Code for CS 440 P2
/*	CS 440 Programming Assignment 2
*
*	Name: Sonya McCree; Yuxuan(Lorraine) Ji
*		  smccree@bu.edu; yuxuanji@bu.edu
*	Date: 2 April 2018
* --------------
References : https://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/template_matching/template_matching.html
for template matching
*/

//opencv libraries
#include "opencv2/core/core.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
//C++ standard libraries
#include <iostream>
#include <vector>
#include <windows.h>

using namespace cv;
using namespace std;

//Global Variables
Mat img; Mat templ;  Mat result;
bool isFist;

Mat templ1 = imread("fist.png", 0); //two template images
Mat templ2 = imread("hand.png", 0);

char* image_window = "Source Image";    //global variables from openCV
char* result_window = "Result window";



int match_method;
int max_Trackbar = 5; //for openCV template matching

					  //function declarations

					  /**
					  Function that returns the maximum of 3 integers
					  @param a first integer
					  @param b second integer
					  @param c third integer
					  */
int myMax(int a, int b, int c);

/**
Function that returns the minimum of 3 integers
@param a first integer
@param b second integer
@param c third integer
*/
int myMin(int a, int b, int c);

/**
Function that detects whether a pixel belongs to the skin based on RGB values
@param src The source color image
@param dst The destination grayscale image where skin pixels are colored white and the rest are colored black
*/
void mySkinDetect(Mat& src, Mat& dst);

/**
Function that does frame differencing between the current frame and the previous frame
@param src The current color image
@param prev The previous color image
@param dst The destination grayscale image where pixels are colored white if the corresponding pixel intensities in the current
and previous image are not the same
*/
void myFrameDifferencing(Mat& prev, Mat& curr, Mat& dst);

/*
Function that accumulates the frame differences for a certain number of pairs of frames
@param mh Vector of frame difference images
@param dst The destination grayscale image to store the accumulation of the frame difference images
*/
void myMotionEnergy(vector<Mat> mh, Mat& dst);


/**
Function that detects blobs from a binary image
@param binaryImg The source binary image (binary image contains pixels labeled 0 or 1 (not 255))
@param blobs Vector to store all blobs, each of which is stored as a vector of 2D x-y coordinates
*/
void FindBinaryLargeObjects(const Mat &binaryImg, vector <vector<Point2i>> &blobs);

/*Function that computes template matching algorithm on 2 images | from opencv tutorial*/
void myTemplateMatching(int, void*);

/*Function that classifies hand gestures*/
void classifyHandShape(Mat& src);

/*function that computes circularity
@param src = source image*/
double computeCircularity(Mat& src);

int main(int argc, char **argv) {

	//----------------
	//a) Reading a stream of images from a webcamera, and displaying the video
	//----------------
	// For more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html
	// open the video camera no. 0
	VideoCapture cap(0);

	// if not successful, exit program
	if (!cap.isOpened())
	{
		cout << "Cannot open the video cam" << endl;
		return -1;
	}

	//create a window called "MyVideoFrame0"
	namedWindow("MyVideo0", WINDOW_AUTOSIZE);
	Mat frame0;

	// read a new frame from video
	bool bSuccess0 = cap.read(frame0);

	//if not successful, break loop
	if (!bSuccess0)
	{
		cout << "Cannot read a frame from video stream" << endl;
	}

	//show the frame in "MyVideo" window
	imshow("MyVideo0", frame0);

	//create a window called "MyVideo"
	namedWindow("MyVideo", WINDOW_AUTOSIZE);
	namedWindow("MyVideoMH", WINDOW_AUTOSIZE);
	namedWindow("Skin", WINDOW_AUTOSIZE);

	vector<Mat> myMotionHistory;
	Mat fMH1, fMH2, fMH3;
	fMH1 = Mat::zeros(frame0.rows, frame0.cols, CV_8UC1);
	fMH2 = fMH1.clone();
	fMH3 = fMH1.clone();
	myMotionHistory.push_back(fMH1);
	myMotionHistory.push_back(fMH2);
	myMotionHistory.push_back(fMH3);

	while (1)
	{
		// read a new frame from video
		Mat frame;
		bool bSuccess = cap.read(frame);
		imshow("MyVideo0", frame);
		//if not successful, break loop
		if (!bSuccess)
		{
			cout << "Cannot read a frame from video stream" << endl;
			break;
		}

		// destination frame
		Mat frameDest;
		frameDest = Mat::zeros(frame.rows, frame.cols, CV_8UC1); //Returns a zero array of same size as src mat, and of type CV_8UC1
																 //----------------
																 //	b) Skin color detection
																 //----------------
		mySkinDetect(frame, frameDest);
		imshow("Skin", frameDest);

		//-------------------
		//   c) Template Matching 
		//-------------------

		namedWindow("Template Image", WINDOW_AUTOSIZE); //creating windows for viewing source/template simages
		namedWindow("Source Image", WINDOW_AUTOSIZE);

		img = frameDest; //image we want to compare to the template
		imshow("Source Image", img);

		//Create windows
		namedWindow(image_window, WINDOW_AUTOSIZE);
		namedWindow(result_window, WINDOW_AUTOSIZE); //used to be CV_WINDOW_AUTOSIZE -- changed it because seemed unnecessary

		classifyHandShape(img);

		//Create Trackbar

		char* trackbar_label = "Method: \n 0: SQDIFF \n 1: SQDIFF NORMED \n 2: TM CCORR \n 3: TM CCORR NORMED \n 4: TM COEFF \n 5: TM COEFF NORMED"; //we can pick a value 0 - 5 on the trackbar
		createTrackbar(trackbar_label, image_window, &match_method, max_Trackbar, myTemplateMatching);

		if (isFist == true) {
			templ = templ1;
			myTemplateMatching(0, 0);
		}
		else {
			templ = templ2;
			myTemplateMatching(0, 0);
		}

		//----------------
		//	d) Background differencing
		//----------------


		//call myFrameDifferencing function
		myFrameDifferencing(frame0, frame, frameDest);
		imshow("MyVideo", frameDest);

		myMotionHistory.erase(myMotionHistory.begin());
		myMotionHistory.push_back(frameDest);
		Mat myMH = Mat::zeros(frame0.rows, frame0.cols, CV_8UC1);

		//----------------
		//  e) Visualizing motion history
		//----------------

		//call myMotionEnergy function
		myMotionEnergy(myMotionHistory, myMH);


		imshow("MyVideoMH", myMH); //show the frame in "MyVideo" window
		frame0 = frame;
		//wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop
		if (waitKey(30) == 27)
		{
			cout << "esc key is pressed by user" << endl;
			break;
		}
		//waitKey(0);
	}

	cap.release();
	return 0;

	//-------------------------
	//Lab 8: Erosion, dilution, pixel labelling
	//-------------------------

	// read image as grayscale
	Mat img = imread("blob.png", 0);
	if (!img.data) {
		cout << "File not found" << std::endl;
		return -1;
	}

	// create windows
	namedWindow("Original");
	namedWindow("binary");
	namedWindow("labelled");
	imshow("Original", img);

	// perform morphological operations to remove small objects (noise) and fill black spots inside objects
	// Documentation on erode and dilate: https://docs.opencv.org/3.1.0/d4/d86/group__imgproc__filter.html

	// initialize structuring element for morphological operations
	int erosion_size = 3;
	Mat element = getStructuringElement(MORPH_RECT, Size(2 * erosion_size + 1, 2 * erosion_size + 1), Point(erosion_size, erosion_size));
	//perform erosions and dilations
	erode(img, img, element);
	dilate(img, img, element);

	dilate(img, img, element);
	erode(img, img, element);
	imshow("morph", img);

	//convert thresholded image to binary image
	Mat binary;
	threshold(img, binary, 0.0, 1.0, THRESH_BINARY); //for component labeling

													 //initialize vector to store all blobs
	vector <vector<Point2i>> blobs;

	//call function that detects blobs and modifies the input binary image to store blob info
	FindBinaryLargeObjects(binary, blobs);

	//display the output                                                         //Use this for screenshots -- visualizations for project report
	Mat output = Mat::zeros(img.size(), CV_8UC3);
	// Randomly color the blobs
	for (size_t i = 0; i < blobs.size(); i++) {
		unsigned char r = 255 * (rand() / (1.0 + RAND_MAX));
		unsigned char g = 255 * (rand() / (1.0 + RAND_MAX));
		unsigned char b = 255 * (rand() / (1.0 + RAND_MAX));

		for (size_t j = 0; j < blobs[i].size(); j++) {
			int x = blobs[i][j].x;
			int y = blobs[i][j].y;

			output.at<Vec3b>(y, x)[0] = b;  //pixels = backward in opencv
			output.at<Vec3b>(y, x)[1] = g;
			output.at<Vec3b>(y, x)[2] = r;
		}
	}


	//show the binary image, as well as the labelled image
	imshow("labelled", output);
	waitKey(0); //keeps the image from disappearing automatically
}


//Function that returns the maximum of 3 integers
int myMax(int a, int b, int c) {
	int m = a;
	(void)((m < b) && (m = b));
	(void)((m < c) && (m = c));
	return m;
}

//Function that returns the minimum of 3 integers
int myMin(int a, int b, int c) {
	int m = a;
	(void)((m > b) && (m = b));
	(void)((m > c) && (m = c));
	return m;
}

//Function that detects whether a pixel belongs to the skin based on RGB values
void mySkinDetect(Mat& src, Mat& dst) {
	//Surveys of skin color modeling and detection techniques:
	//Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. "A survey on pixel-based skin color detection techniques." Proc. Graphicon. Vol. 3. 2003.
	//Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. "A survey of skin-color modeling and detection methods." Pattern recognition 40.3 (2007): 1106-1122.
	for (int i = 0; i < src.rows; i++) {
		for (int j = 0; j < src.cols; j++) {
			//For each pixel, compute the average intensity of the 3 color channels
			Vec3b intensity = src.at<Vec3b>(i, j); //Vec3b is a vector of 3 uchar (unsigned character)
			int B = intensity[0]; int G = intensity[1]; int R = intensity[2];
			if ((R > 95 && G > 40 && B > 20) && (myMax(R, G, B) - myMin(R, G, B) > 15) && (abs(R - G) > 15) && (R > G) && (R > B)) {
				dst.at<uchar>(i, j) = 255; //RGB values refer to a range of possible skin tones --> way to reduce noise/improve accuracy?
			}
		}
	}
}


//Function that does frame differencing between the current frame and the previous frame
void myFrameDifferencing(Mat& prev, Mat& curr, Mat& dst) {
	//For more information on operation with arrays: http://docs.opencv.org/modules/core/doc/operations_on_arrays.html
	absdiff(prev, curr, dst);
	Mat cp = dst.clone();
	cvtColor(dst, cp, CV_BGR2GRAY);
	dst = cp > 50;
}

//Function that accumulates the frame differences for a certain number of pairs of frames
void myMotionEnergy(vector<Mat> mh, Mat& dst) {
	Mat mh0 = mh[0];
	Mat mh1 = mh[1];
	Mat mh2 = mh[2];

	int count = 0;
	for (int i = 0; i < dst.rows; i++) {
		for (int j = 0; j < dst.cols; j++) {
			if (mh0.at<uchar>(i, j) == 255 || mh1.at<uchar>(i, j) == 255 || mh2.at<uchar>(i, j) == 255) {
				dst.at<uchar>(i, j) = 255;
				count++;
			}
		}
	}
	if (count>30000 && isFist == false) { //modified part of motion energy function
		putText(dst, "Waving", Point2f(50, 50), FONT_HERSHEY_SCRIPT_SIMPLEX, 2, Scalar(255, 255, 255), 2, LINE_AA); //show text "Waving" at random spot on screen
																													//cout << "Wave!";
		return;
	}
	else {
		putText(dst, "", Point2f(50, 230), FONT_HERSHEY_SCRIPT_SIMPLEX, 2, Scalar(255, 255, 255), 2, LINE_AA); //clear text
		return;
	}
}


/*Function that computes template matching algorithm on 2 images
from openCV tutorial
*/
void myTemplateMatching(int, void*) {
	//Source image to display
	Mat img_display;
	imshow("Template Image", templ);
	img.copyTo(img_display);

	//Create the result matrices
	int result_cols = img.cols - templ.cols + 1;
	int result_rows = img.rows - templ.rows + 1;

	Mat result;

	result.create(result_rows, result_cols, CV_8UC1);

	//Do the Matching and Normalize
	matchTemplate(img, templ, result, match_method);
	normalize(result, result, 0, 1, NORM_MINMAX, -1, Mat());

	//Localizing the best match with minMaxLoc
	double minVal; double maxVal; Point minLoc; Point maxLoc;
	Point matchLoc;

	minMaxLoc(result, &minVal, &maxVal, &minLoc, &maxLoc, Mat());

	cout << maxVal << endl;
	//For SQDIFF and SQDIFF_NORMED, the best matches are lower values. For all the other methods, the higher the better
	if (match_method == CV_TM_SQDIFF || match_method == CV_TM_SQDIFF_NORMED)
	{
		matchLoc = minLoc;
	}
	else
	{
		matchLoc = maxLoc;
	}

	//Show me what you got
	rectangle(img_display, matchLoc, Point(matchLoc.x + templ.cols, matchLoc.y + templ.rows), Scalar(255, 255, 255), 2, 8, 0);
	rectangle(result, matchLoc, Point(matchLoc.x + templ.cols, matchLoc.y + templ.rows), Scalar(255, 255, 255), 2, 8, 0);

	imshow(image_window, img_display);
	imshow(result_window, result);

	return;
}

/*From lab 8*/
void FindBinaryLargeObjects(const Mat &binary, vector <vector<Point2i>> &blobs)
{
	//clear blobs vector
	blobs.clear();

	//labelled image of type CV_32SC1
	Mat label_image;
	binary.convertTo(label_image, CV_32SC1); //CV_32SC1 is int type

											 //label count starts at 2
	int label_count = 2;
	//iterate over all pixels until a pixel with a 1-value is encountered
	for (int y = 0; y < label_image.rows; y++) {
		for (int x = 0; x < label_image.cols; x++) {   //iterating through coordinates, so x,y used instead of i,j | 
													   //check if the pixel is 1
			if (label_image.at<int>(y, x) != 1) {
				continue;
			}
			Rect rect;
			floodFill(label_image, Point(x, y), label_count, &rect, 0, 0, 4); //creates bounding box

			vector <Point2i> blob;
			for (int i = rect.y; i < rect.y + rect.height; i++) {
				for (int j = rect.x; j < rect.x + rect.width; j++) {
					if (label_image.at<int>(i, j) != label_count) {  //finds all adjacent pixels of the blob and changes value to label_count
						continue;
					}
					blob.push_back(Point2i(j, i)); //save blob
				}
			}
			label_count++;
			blobs.push_back(blob);  //moving on to the next blob~
		}
	}

	cout << "The number of blobs in the image is: " << blobs.size() << endl;
	//Code derived from: http://nghiaho.com/
}

/*function that computes circularity
Formula: circularity = Emin / Emax --> more circular if closer to 1

Emin = a + c / 2 - (a - c) ^2 / 2h - b^2 / 2h

Emax = a + c / 2 + (a - c)^2 / 2h + b^2 / 2h

a = M(2,0) b = 2(M(1,1) c = M(0, 2)*/
double computeCircularity(Mat& src) {
	//find moments
	Moments moment = moments(src);

	double a = moment.mu20;
	double b = 2 * (moment.mu11);
	double c = moment.mu02;

	//compute circularity
	double h = sqrt(pow((a - c), 2) + pow(b, 2));
	double Emin = ((a + c) / 2) - (pow((a - c), 2) / (2 * h)) - pow(b, 2) / (2 * h);
	double Emax = ((a + c) / 2) + (pow((a - c), 2) / (2 * h)) + pow(b, 2) / (2 * h);

	double circularity = (Emin / Emax);

	return circularity;
}

/*Function that computes circularity
@param src = source image*/
void classifyHandShape(Mat& src) {
	//compute circularity of shape blobs (templates and gesture)

	double src_circ = computeCircularity(src);
	double fist_circ = computeCircularity(templ1);
	double hand_circ = computeCircularity(templ2);

	cout << "Source Circularity: " << src_circ << endl;
	cout << "Fist Circularity: " << fist_circ << endl;
	cout << "Hand Circularity: " << hand_circ << endl << endl;

	//fist_circ = fist_circ / 2;
	//hand_circ = hand_circ / 2;

	//compare circularity
	double diff_fist = abs(src_circ - fist_circ);
	double diff_hand = abs(src_circ - hand_circ);

	if (diff_fist < diff_hand) {
		isFist = true;
		cout << "This is a fist." << endl;
	}
	else if (diff_fist > diff_hand) {
		isFist = false;
		cout << "This is a hand." << endl;
	}
	else {
		cout << "Result inconclusive." << endl;
	}
}
